{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e696d2ee",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mydearlutein/tutorial-ai-hub-car-damage-recognition/blob/main/demo/openai_interface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fyFvgXWh4Yar",
   "metadata": {
    "id": "fyFvgXWh4Yar"
   },
   "source": [
    "# Prompting practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pl-Pc76r3zem",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pl-Pc76r3zem",
    "outputId": "09bcfbb7-1cf8-4413-db4d-509478e3159b"
   },
   "outputs": [],
   "source": [
    "!pip install -q langchain sseclient gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d10XVKEd4s7b",
   "metadata": {
    "id": "d10XVKEd4s7b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "import sseclient\n",
    "from typing import Any, List, Mapping, Optional\n",
    "\n",
    "# os.environ['OPENAI_API_KEY'] = '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'  # LG CNS AI Engineering Lab\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "\n",
    "def request_chatgpt(model_name: str, prompt: str) -> str:\n",
    "    response = requests.post(\n",
    "        \"https://api.openai.com/v1/chat/completions\",\n",
    "        headers={\"Authorization\": f\"Bearer {os.getenv('OPENAI_API_KEY')}\"},\n",
    "        json={\"model\": f\"{model_name}\", \"messages\": [{\"role\": \"user\", \"content\": f\"{prompt}\"}]},\n",
    "    )\n",
    "    # print(response.json())\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "def arequest_chatgpt(model_name: str, prompt: str) -> str:\n",
    "    response = requests.post(\n",
    "        \"https://api.openai.com/v1/chat/completions\",\n",
    "        headers={\"Authorization\": f\"Bearer {os.getenv('OPENAI_API_KEY')}\", \"Accept\": \"text/event-stream\"},\n",
    "        json={\"model\": f\"{model_name}\", \"messages\": [{\"role\": \"user\", \"content\": f\"{prompt}\"}], \"stream\": True},\n",
    "        stream=True,\n",
    "    )\n",
    "    client = sseclient.SSEClient(response)\n",
    "    for event in client.events():\n",
    "        if event.data != '[DONE]':\n",
    "            # print(json.loads(event.data)['choices'][0], end=\"\", flush=True)  # {'index': 0, 'delta': {'role': 'assistant', 'content': ''}, 'finish_reason': None}\n",
    "            yield json.loads(event.data)['choices'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "RGgVtHie3-4i",
   "metadata": {
    "id": "RGgVtHie3-4i"
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "prompt = \"\"\"You are a call center agent working for a autonomous insurance company.\n",
    "You will receive the information of the damanged car in <INFO> section. The information given includes the type of damage, the production year of the damaged car and the color of the damaged car.\n",
    "You must describe the status of the car and estimate the repair cost and inform to your customer.\n",
    "When you estimate the repair cost, you can refer to the repair cost below in <REPAIR PRICE>. The unit of price is Korean WON.\n",
    "Please make your suggestion nicely and warmly in KOREAN.\n",
    "\n",
    "---\n",
    "<REPAIR PRICE>\n",
    "| Production year\\Type of damage | 2005 ~ 2008    | 2009    | 2010    | 2011~    |\n",
    "|--------------------------------|----------------|---------|---------|----------|\n",
    "| Scratched                      |        500,000 | 500,000 | 300,000 |  200,000 |\n",
    "| Seperated                      |      1,000,000 | 800,000 | 700,000 |  600,000 |\n",
    "</REPAIR PRICE>\n",
    "\n",
    "---\n",
    "<EXAMPLES>\n",
    "Given information: {\n",
    "    \"damage\": \"Scratched\",\n",
    "    \"production year\": 2018,\n",
    "    \"color\": \"White\",\n",
    "}\n",
    "Suggestions: 새하얀 차에 스크래치가 나셨군요. 속상 하시겠어요. 2018년식 자동차 기준으로 해당 스크래치 수리비는 약 20만원 정도가 나올 것으로 예상됩니다.\n",
    "</EXAMPLES>\n",
    "\n",
    "---\n",
    "<INFO>\n",
    "{{info}}\n",
    "</INFO>\n",
    "\n",
    "Suggestions:\n",
    "\"\"\"\n",
    "\n",
    "def generate(label: Dict):\n",
    "    formatted_prompt = prompt.replace(\"{{info}}\", str(label))\n",
    "    answer = request_chatgpt(\"gpt-3.5-turbo\", formatted_prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "946af4ef-06df-410d-8bfd-eda45696b025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function posixpath.basename(p)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e928177b-7d04-4e61-8f72-031f037ee633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# sample_img_dir = os.path.join(os.path.dirname(os.getcwd()), 'work/data/samples/1.원천데이터/damage/')\n",
    "# sample_img_dir = 'work/data/samples/1.원천데이터/damage/'\n",
    "# sample_imgs = os.listdir(sample_img_dir)\n",
    "# sample_imgs[:5]\n",
    "# sample_img_dir\n",
    "samples = glob.glob('/home/jovyan/work/data/samples/1.원천데이터/damage/*.jpg')\n",
    "samples[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "_VAa0c1DQrN2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "id": "_VAa0c1DQrN2",
    "outputId": "0d501bb0-7682-409d-9140-4ad061fcc9cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Running on local URL:  http://0.0.0.0:7875\n",
      "Running on public URL: https://66922a233590bf6444.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://66922a233590bf6444.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/gradio/routes.py\", line 534, in predict\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/gradio/blocks.py\", line 1554, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/gradio/blocks.py\", line 1192, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/gradio/utils.py\", line 659, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_65/2265925822.py\", line 18, in predict\n",
      "    response = generate(information)\n",
      "  File \"/tmp/ipykernel_65/2911105003.py\", line 37, in generate\n",
      "    answer = request_chatgpt(\"gpt-3.5-turbo\", formatted_prompt)\n",
      "  File \"/tmp/ipykernel_65/2803868344.py\", line 17, in request_chatgpt\n",
      "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
      "KeyError: 'choices'\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import gradio as gr\n",
    "import json\n",
    "\n",
    "def predict(image):\n",
    "\n",
    "    # (TODO)segmentation 모델 적용 필요 - 우선 임시 코드\n",
    "    sample_label = '/home/jovyan/work/data/samples/2.라벨링데이터/damage/0002010_as-0097507.json'\n",
    "    # sample_label = glob.glob(os.path.join(os.path.dirname(os.getcwd()), 'data/samples/2.라벨링데이터/damage', r\"*.json\"))[0]\n",
    "    # with open(os.path.join(os.path.abspath('damaged_cars/samples'), \"0000459_sc-226797.json\")) as f:\n",
    "    with open(sample_label, 'r') as f:\n",
    "        json_label = json.load(f)\n",
    "\n",
    "    # ChatGPT에 제공할 정보 가공\n",
    "    information = {key: val for key, val in json_label[\"annotations\"][0].items() if key in [\"damage\", \"year\", \"color\"]}\n",
    "\n",
    "    # (TODO) chatgpt call - 우선 임시 코드\n",
    "    response = generate(information)\n",
    "\n",
    "    return information, response\n",
    "\n",
    "\n",
    "sample_files = glob.glob(os.path.join(os.path.dirname(os.getcwd()), 'data/samples/1.원천데이터/damage', r\"*.jpg\"))\n",
    "sample_files = sample_files[:4]\n",
    "print(sample_files)\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=[\n",
    "        gr.Json(label=\"json_label\"),\n",
    "        gr.TextArea(label=\"ChatGPT Answer\"),\n",
    "    ],\n",
    "    # flagging_options=[\"correct\", \"incorrect\", \"other\"],\n",
    "    # examples=[\n",
    "    #     os.path.join(os.path.abspath('damaged_cars/samples'), \"0000459_sc-226797.jpg\"),\n",
    "    #     os.path.join(os.path.abspath('damaged_cars/samples'), \"0000802_as-7929891.jpg\"),\n",
    "    #     os.path.join(os.path.abspath('damaged_cars/samples'), \"0001061_sc-123724.jpg\"),\n",
    "    #     os.path.join(os.path.abspath('damaged_cars/samples'), \"0001146_sc-149689.jpg\"),\n",
    "    # ],\n",
    "    examples=[os.path.join(os.path.dirname(os.getcwd()),'data/samples/1.원천데이터/damage/0000459_sc-226797.jpg')],\n",
    "    # examples=sample_files\n",
    ")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(server_name='0.0.0.0', share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3_8azp4H4tMb",
   "metadata": {
    "id": "3_8azp4H4tMb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
